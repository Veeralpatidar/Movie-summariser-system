{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":24465,"sourceType":"datasetVersion","datasetId":18754},{"sourceId":10090044,"sourceType":"datasetVersion","datasetId":6221691},{"sourceId":10098820,"sourceType":"datasetVersion","datasetId":6226957},{"sourceId":11714874,"sourceType":"datasetVersion","datasetId":7353428},{"sourceId":259041520,"sourceType":"kernelVersion"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install rouge-score -q\n!pip install networkx -q\n!pip install sentencepiece","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T12:21:07.972036Z","iopub.execute_input":"2025-08-30T12:21:07.973217Z","iopub.status.idle":"2025-08-30T12:21:20.310908Z","shell.execute_reply.started":"2025-08-30T12:21:07.973137Z","shell.execute_reply":"2025-08-30T12:21:20.309659Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"\"\"\"\nROUGE alignment script + Notebook (script-style) to generate training and inference datasets\nfor wb_script_summarizer.py on Kaggle.\n\nThis file includes two deliverables in one file:\n\n1) rouge_align.py (module functions + CLI) - greedy ROUGE alignment to create sentence-level labels\n   Usage: python rouge_align.py --script script.txt --reference reference.txt --top_k 3 --out script.labels.json\n\n2) notebook-style pipeline (cells with # %%) that:\n   - downloads required Kaggle datasets (Cornell, IMSDb scripts, OpenSubtitles) via slugs,\n   - downloads CMU Movie Summary Corpus (Kaggle slug used as fallback),\n   - downloads SAMSum via HuggingFace datasets,\n   - runs alignment to produce .txt + .labels.json files compatible with wb_script_summarizer.py,\n   - builds a simple vocab (simple_vocab.json) and shows a demo inference using wb_script_summarizer.\n\nNotes:\n- Requires: rouge-score, datasets, tqdm, transformers (optional), scikit-learn (optional for fallback), networkx/matplotlib (for graphing demo).\n- On Kaggle: the `kaggle` CLI is available; you can also attach datasets in the UI and pass local dirs instead of slugs.\n\n\"\"\"\n\n# ----------------------\n# Part A: ROUGE alignment utility (greedy selection)\n# ----------------------\n\nimport argparse\nimport json\nimport os\nimport re\nfrom typing import List, Tuple\n\ntry:\n    from rouge_score import rouge_scorer\n    ROUGE_AVAILABLE = True\nexcept Exception:\n    ROUGE_AVAILABLE = False\n\n\ndef sentence_split(text: str) -> List[str]:\n    \"\"\"Naive sentence splitter used for scripts and dialogues.\"\"\"\n    text = text.replace('\\r', '\\n')\n    sents = re.split(r'(?<=[.!?\\n])\\s+', text)\n    sents = [s.strip() for s in sents if s.strip()]\n    return sents\n\n\ndef compute_rouge_gain(candidate: str, reference: str, scorer) -> float:\n    # returns rouge-l fmeasure as the score\n    scores = scorer.score(reference, candidate)\n    # score returns dict with keys like 'rouge1','rougeL' etc., values with precision/recall/fmeasure\n    return scores['rougeL'].fmeasure\n\n\ndef greedy_rouge_select(sentences: List[str], reference: str, k: int = 3) -> List[int]:\n    \"\"\"Greedy selection of up to k sentences that maximize ROUGE-L against the reference summary.\n    Returns list of selected sentence indices.\n    \"\"\"\n    if not ROUGE_AVAILABLE:\n        raise RuntimeError('rouge_score package is required for greedy_rouge_select. Install via `pip install rouge-score`.')\n    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n    selected = []\n    cur_text = ''\n    cur_score = 0.0\n    for _ in range(k):\n        best_gain = 0.0\n        best_idx = None\n        for i, s in enumerate(sentences):\n            if i in selected:\n                continue\n            cand = (cur_text + ' ' + s).strip() if cur_text else s\n            score = compute_rouge_gain(cand, reference, scorer)\n            gain = score - cur_score\n            if gain > best_gain:\n                best_gain = gain\n                best_idx = i\n        if best_idx is None:\n            break\n        # update\n        selected.append(best_idx)\n        cur_text = (cur_text + ' ' + sentences[best_idx]).strip() if cur_text else sentences[best_idx]\n        cur_score = compute_rouge_gain(cur_text, reference, scorer)\n    return selected\n\n\ndef align_script_to_summary(script_text: str, reference_summary: str, top_k: int = 3) -> List[int]:\n    sents = sentence_split(script_text)\n    if len(sents) == 0:\n        return []\n    ids = greedy_rouge_select(sents, reference_summary, k=top_k)\n    return ids\n\n\n# CLI wrapper for single-file usage\ndef rouge_cli():\n    parser = argparse.ArgumentParser(description='ROUGE-based greedy labeling for extractive summarization')\n    parser.add_argument('--script', type=str, required=True, help='Path to script/text file to label')\n    parser.add_argument('--reference', type=str, required=True, help='Path to reference summary (text file)')\n    parser.add_argument('--top_k', type=int, default=3, help='Number of sentences to select')\n    parser.add_argument('--out', type=str, default=None, help='Output .labels.json file path')\n    args = parser.parse_args()\n\n    script_text = open(args.script, 'r', encoding='utf-8').read()\n    ref_text = open(args.reference, 'r', encoding='utf-8').read()\n    sel = align_script_to_summary(script_text, ref_text, top_k=args.top_k)\n    outp = args.out or args.script.replace('.txt', '.labels.json')\n    with open(outp, 'w', encoding='utf-8') as fo:\n        json.dump({'important_sentence_indices': sel}, fo)\n    print('Wrote labels to', outp)\n\n\n# ----------------------\n# Part B: Notebook-style pipeline (cells with # %% separators)\n# ----------------------","metadata":{"_uuid":"48ad382d-0cf0-4182-bbfa-c8340d4d7cfb","_cell_guid":"55061c47-b580-4e69-bb95-8c9f7d0c73e8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-30T12:21:31.171128Z","iopub.execute_input":"2025-08-30T12:21:31.171510Z","iopub.status.idle":"2025-08-30T12:21:32.938261Z","shell.execute_reply.started":"2025-08-30T12:21:31.171477Z","shell.execute_reply":"2025-08-30T12:21:32.937018Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Notebook: Full pipeline to produce training and inference datasets\n# Save this file as `movie_pipeline_notebook.py` or paste cells into a Kaggle notebook.","metadata":{"_uuid":"05f7ff14-096b-46fd-804b-d195d6f412eb","_cell_guid":"c47ec0f0-28be-4036-8d56-fd6a0d5246e2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-30T12:21:43.992975Z","iopub.execute_input":"2025-08-30T12:21:43.993465Z","iopub.status.idle":"2025-08-30T12:21:43.998042Z","shell.execute_reply.started":"2025-08-30T12:21:43.993436Z","shell.execute_reply":"2025-08-30T12:21:43.997089Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Cell 1: Install dependencies (run in Kaggle notebook cell)\nINSTALL_CMD = '''\n# If running on a new kernel, uncomment these\n# !pip install --quiet rouge-score datasets transformers tqdm scikit-learn\n'''\nprint('If you need dependencies, run the following in a notebook cell:')\nprint(INSTALL_CMD)","metadata":{"_uuid":"d9a3385d-8a43-4df7-80d0-980e4d597f1f","_cell_guid":"99323d0f-272c-4221-bee0-e264643933cc","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-30T12:21:47.452459Z","iopub.execute_input":"2025-08-30T12:21:47.452849Z","iopub.status.idle":"2025-08-30T12:21:47.458915Z","shell.execute_reply.started":"2025-08-30T12:21:47.452820Z","shell.execute_reply":"2025-08-30T12:21:47.457613Z"}},"outputs":[{"name":"stdout","text":"If you need dependencies, run the following in a notebook cell:\n\n# If running on a new kernel, uncomment these\n# !pip install --quiet rouge-score datasets transformers tqdm scikit-learn\n\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Cell 2: Imports\nimport subprocess\nimport shutil\nfrom pathlib import Path\nfrom datasets import load_dataset\nfrom tqdm import tqdm\n\n# local helpers from above","metadata":{"_uuid":"92b15ed8-0f0c-4d55-8f73-78237fe6a7bc","_cell_guid":"d2472c61-2b18-4698-87b8-728bcd2fa6e1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-30T12:21:57.425762Z","iopub.execute_input":"2025-08-30T12:21:57.426638Z","iopub.status.idle":"2025-08-30T12:21:59.800042Z","shell.execute_reply.started":"2025-08-30T12:21:57.426602Z","shell.execute_reply":"2025-08-30T12:21:59.798818Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Cell 3: Kaggle dataset slugs (pre-validated)\nKAGGLE_CORPUS_SLUG = 'rajathmc/cornell-moviedialog-corpus'  # Cornell\nKAGGLE_SCRIPTS_SLUG = 'veeralakrishna/imsdb-movie-scripts'  # IMSDb scripts\nKAGGLE_SUBTITLES_SLUG = 'kaushikrahul/english-subtitles-opensubtitles-org'  # OpenSubtitles (English)\nKAGGLE_CMU_SUMMARIES_SLUG = 'srikarmell/cmu-movie-summary-corpus'  # CMU Movie Summary (Kaggle mirror)\n\nprint('Using Kaggle slugs:')\nprint(KAGGLE_CORPUS_SLUG)\nprint(KAGGLE_SCRIPTS_SLUG)\nprint(KAGGLE_SUBTITLES_SLUG)\nprint(KAGGLE_CMU_SUMMARIES_SLUG)","metadata":{"_uuid":"a6bbb6b2-ee38-4422-939c-81d7ea264883","_cell_guid":"5b08b6d4-de1a-4579-bdc3-f7c6128557cf","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-30T12:22:02.801744Z","iopub.execute_input":"2025-08-30T12:22:02.802471Z","iopub.status.idle":"2025-08-30T12:22:02.809674Z","shell.execute_reply.started":"2025-08-30T12:22:02.802434Z","shell.execute_reply":"2025-08-30T12:22:02.807589Z"}},"outputs":[{"name":"stdout","text":"Using Kaggle slugs:\nrajathmc/cornell-moviedialog-corpus\nveeralakrishna/imsdb-movie-scripts\nkaushikrahul/english-subtitles-opensubtitles-org\nsrikarmell/cmu-movie-summary-corpus\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Cell 5: Prepare SAMSum (HuggingFace) as extractive-labeled dialogue data\nprint('Loading SAMSum via HuggingFace datasets...')\ntry:\n    samsum = load_dataset('knkarthick/samsum')\nexcept Exception as e:\n    print('Failed to download samsum via datasets.load_dataset():', e)\n    samsum = None","metadata":{"_uuid":"a5dbaef0-d949-4685-bb82-f996c3ce0681","_cell_guid":"fb54ced2-445a-466b-ab2c-74e53b8964a0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-30T12:58:16.428814Z","iopub.execute_input":"2025-08-30T12:58:16.429121Z","iopub.status.idle":"2025-08-30T12:58:19.206820Z","shell.execute_reply.started":"2025-08-30T12:58:16.429099Z","shell.execute_reply":"2025-08-30T12:58:19.205964Z"}},"outputs":[{"name":"stdout","text":"Loading SAMSum via HuggingFace datasets...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74501f1949d74220a3a469dc8ee84c40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train.csv: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27cff57faee64500937bfe8f78739a98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation.csv: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfe445e422974e1ab715eff87ec3e6ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test.csv: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b726173d80d34f6a80bec49e2058fe87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/14732 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed98e1e3697742f6beea862b44772fd3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/818 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cab43f12d204d44a25dbeec62b3e676"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/819 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01d69a1c6e8b4e0abeecd6e0075e26fc"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# Cell 6: Convert SAMSum to per-dialogue .txt and .labels.json using greedy ROUGE\nif samsum is not None:\n    samsum_out = OUT_DIR / 'samsum_prepared'\n    samsum_out.mkdir(parents=True, exist_ok=True)\n    from rouge_score import rouge_scorer\n    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n\n    def make_labels_for_dialogue(dialogue: str, summary: str, top_k: int = 3):\n        sents = sentence_split(dialogue)\n        if len(sents) == 0:\n            return []\n        return greedy_rouge_select(sents, summary, k=top_k)\n\n    for split in ['train', 'validation', 'test']:\n        if split not in samsum:\n            continue\n        for i, ex in enumerate(tqdm(samsum[split])):\n            dialogue = ex['dialogue']\n            summary = ex['summary']\n            # save dialogue as a text file (one line per utterance)\n            fname = samsum_out / f'samsum_{split}_{i:06d}.txt'\n            with open(fname, 'w', encoding='utf-8') as fo:\n                fo.write(str(dialogue))\n            # compute labels\n            try:\n                sel = make_labels_for_dialogue(dialogue, summary, top_k=3)\n            except Exception as e:\n                sel = []\n            labp = str(fname).replace('.txt', '.labels.json')\n            with open(labp, 'w', encoding='utf-8') as fo:\n                json.dump({'important_sentence_indices': sel}, fo)\n    print('SAMSum converted to', samsum_out)","metadata":{"_uuid":"66cdc862-0407-4a08-9a46-c3a039f30e1d","_cell_guid":"deba3750-9beb-48d1-a516-7867d9fe3564","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-30T13:05:25.022294Z","iopub.execute_input":"2025-08-30T13:05:25.022605Z","iopub.status.idle":"2025-08-30T13:10:17.940396Z","shell.execute_reply.started":"2025-08-30T13:05:25.022580Z","shell.execute_reply":"2025-08-30T13:10:17.939392Z"}},"outputs":[{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14732/14732 [04:23<00:00, 55.86it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 818/818 [00:14<00:00, 57.03it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 819/819 [00:14<00:00, 55.33it/s]","output_type":"stream"},{"name":"stdout","text":"SAMSum converted to /kaggle/working/preprocessed/samsum_prepared\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Cell 7: Prepare CMU Movie Summary corpus and align to IMSDb scripts (domain-specific labeling)\n# Note: this step tries to match script filenames to CMU titles by fuzzy matching. It may not find matches for all scripts.\n\nimport glob\nfrom difflib import SequenceMatcher\n\ncmu_dir = Path(\"/kaggle/input/cmu-movie-summary-corpus\")\ncmu_dir_exists = cmu_dir.exists()\nif cmu_dir_exists:\n    # load CMU summaries (assumes CSV/TSV or text files in the downloaded folder)\n    # Try to find a file named 'plot_summaries.txt' or similar\n    possible = list(cmu_dir.rglob('*plot*')) + list(cmu_dir.rglob('*.csv')) + list(cmu_dir.rglob('*.tsv'))\n    cmu_entries = []\n    for p in possible:\n        try:\n            txt = p.read_text(encoding='utf-8', errors='ignore')\n            # naive parsing: lines with tab-separated movieid \\t plot\n            for line in txt.splitlines():\n                parts = line.split('\\t')\n                if len(parts) >= 2:\n                    title = parts[0].strip()\n                    plot = '\\t'.join(parts[1:]).strip()\n                    cmu_entries.append({'title': title, 'plot': plot})\n        except Exception:\n            continue\n    print('Loaded', len(cmu_entries), 'CMU entries (approx)')\nelse:\n    print('CMU summaries not found at', cmu_dir, \"â€” if running on Kaggle, download the '\" + KAGGLE_CMU_SUMMARIES_SLUG + \"' dataset or provide a local CMU folder.\")\n\n# Now try to align to scripts in scripts_raw produced by preprocess_kaggle.py\nscripts_raw_dir = Path(\"/kaggle/input/imsdb-movie-scripts\")\nif scripts_raw_dir.exists():\n    out_align_dir = OUT_DIR / 'scripts_with_labels'\n    out_align_dir.mkdir(parents=True, exist_ok=True)\n    for script_path in scripts_raw_dir.glob('*.txt'):\n        name = script_path.stem.lower()\n        # find best matching CMU title via simple substring or sequence matcher\n        best = None\n        best_score = 0.0\n        for e in cmu_entries:\n            title = e['title'].lower()\n            # prefer substring match\n            if title and title in name:\n                best = e\n                best_score = 1.0\n                break\n            # else fuzzy\n            seq = SequenceMatcher(None, title, name).ratio()\n            if seq > best_score:\n                best_score = seq\n                best = e\n        if best and best_score > 0.6:\n            # align using greedy ROUGE\n            script_text = script_path.read_text(encoding='utf-8', errors='ignore')\n            try:\n                sel = align_script_to_summary(script_text, best['plot'], top_k=5)\n            except Exception:\n                sel = []\n            dest = out_align_dir / script_path.name\n            shutil.copy(script_path, dest)\n            labp = str(dest).replace('.txt', '.labels.json')\n            with open(labp, 'w', encoding='utf-8') as fo:\n                json.dump({'important_sentence_indices': sel}, fo)\n    print('Aligned scripts saved to', out_align_dir)\nelse:\n    print('No scripts_raw dir found at', scripts_raw_dir, 'â€” run preprocess_kaggle.py first to populate it.')","metadata":{"_uuid":"278807d2-87e7-4b2b-8242-67092ab59d9a","_cell_guid":"369b37fc-4b47-4e93-abf2-1d6ce44d3ed3","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-30T13:12:16.213735Z","iopub.execute_input":"2025-08-30T13:12:16.214069Z","iopub.status.idle":"2025-08-30T13:12:17.899698Z","shell.execute_reply.started":"2025-08-30T13:12:16.214043Z","shell.execute_reply":"2025-08-30T13:12:17.898610Z"}},"outputs":[{"name":"stdout","text":"Loaded 124047 CMU entries (approx)\nAligned scripts saved to /kaggle/working/preprocessed/scripts_with_labels\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Cell 8: Build simple vocab from produced datasets (samsum_prepared + scripts_with_labels + cornell convs)\nfrom collections import Counter\nimport re\n\nvocab_out = OUT_DIR / 'simple_vocab.json'\npat = re.compile(r\"\\w+|[^\\s\\w]\")\n\nsources = []\nif (OUT_DIR / 'samsum_prepared').exists():\n    sources.append(OUT_DIR / 'samsum_prepared')\nif (OUT_DIR / 'scripts_with_labels').exists():\n    sources.append(OUT_DIR / 'scripts_with_labels')\nif (OUT_DIR / 'cornell_conversations').exists():\n    sources.append(OUT_DIR / 'cornell_conversations')\n\ncounter = Counter()\nfor d in sources:\n    for p in d.glob('*.txt'):\n        txt = p.read_text(encoding='utf-8', errors='ignore')\n        toks = pat.findall(txt)\n        counter.update(toks)\n\nvocab = {'<unk>': 0}\nnext_id = 1\nfor tok, _ in counter.most_common():\n    vocab[tok] = next_id\n    next_id += 1\nwith open(vocab_out, 'w', encoding='utf-8') as fo:\n    json.dump(vocab, fo)\nprint('Saved vocab to', vocab_out, 'size=', len(vocab))","metadata":{"_uuid":"1bed161b-bb7e-4d32-b804-992c83e2321b","_cell_guid":"b951cf9c-7b3d-40e2-8ae6-e53d872dcd66","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-30T13:15:41.292061Z","iopub.execute_input":"2025-08-30T13:15:41.293016Z","iopub.status.idle":"2025-08-30T13:15:43.211657Z","shell.execute_reply.started":"2025-08-30T13:15:41.292979Z","shell.execute_reply":"2025-08-30T13:15:43.210608Z"}},"outputs":[{"name":"stdout","text":"Saved vocab to /kaggle/working/preprocessed/simple_vocab.json size= 37649\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Cell 9: Quick demo - run infer_summary on a SAMSum example using wb_script_summarizer (random-initialized model)\n# Assumes wb_script_summarizer.py is in working dir\ntry:\n    import script_summarizer as wbs\n    # load vocab\n    tok = wbs.SimpleTokenizer(vocab=vocab)\n    # tiny model for demo\n    model = wbs.SummarizerModel(vocab_size=len(vocab), d_model=128, num_layers=2, nhead=4)\n    # pick one samsum file if exists\n    samsum_dir = OUT_DIR / 'samsum_prepared'\n    if samsum_dir.exists():\n        sample = next(samsum_dir.glob('samsum_train_*.txt'))\n        text = sample.read_text(encoding='utf-8')\n        summary, sentences, scores, attn_maps = wbs.infer_summary(model, tok, text, top_k=3, device='cpu')\n        print('INFERRED SUMMARY:\\n', summary)\n    else:\n        print('No samsum_prepared found; run earlier cells to generate it.')\nexcept Exception as e:\n    print('Demo failed (is wb_script_summarizer.py present?):', e)","metadata":{"_uuid":"ea60150a-8dde-4733-a0dd-4d23bb2c9fb5","_cell_guid":"8c5b54d7-3bea-4518-b572-59b569565825","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-30T13:15:49.365831Z","iopub.execute_input":"2025-08-30T13:15:49.366170Z","iopub.status.idle":"2025-08-30T13:15:49.695533Z","shell.execute_reply.started":"2025-08-30T13:15:49.366121Z","shell.execute_reply":"2025-08-30T13:15:49.694499Z"}},"outputs":[{"name":"stdout","text":"INFERRED SUMMARY:\n Burton: Did u manage to get some money? I feel so guilty to lie to my mumðŸ˜¢\nAlfio: I told her I need new reference book at schoolðŸ˜¢\nBurton: Oh no.....(ToT)/~~~\nAlfio: But now I can get the concert ticket. ðŸ‘‹\nAlfio: I dont wanna think about anything else for now\tðŸ‘‹\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# End of notebook\nprint('Pipeline cells prepared. On Kaggle: run each cell sequentially (or paste into a notebook) to produce training and inference datasets.')","metadata":{"_uuid":"604f9a88-67f4-482a-8075-93f2276d78bd","_cell_guid":"3a34ebc8-7087-45c5-a665-83f95d6809f7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-30T13:17:33.620204Z","iopub.execute_input":"2025-08-30T13:17:33.620632Z","iopub.status.idle":"2025-08-30T13:17:33.626666Z","shell.execute_reply.started":"2025-08-30T13:17:33.620604Z","shell.execute_reply":"2025-08-30T13:17:33.625362Z"}},"outputs":[{"name":"stdout","text":"Pipeline cells prepared. On Kaggle: run each cell sequentially (or paste into a notebook) to produce training and inference datasets.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}